<!doctype html>
<html
  lang="en-us"
  dir="ltr"
>
  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    <meta charset="utf-8" />
<meta name="language" content="en" />
<meta name="viewport" content="width=device-width" />
<title>
    LLM Explainer | RJChow&#39;s Notes
</title>
  <meta name="description" content="There’s been quite a few articles that’s been written about AI all over the internet, with various technical depths and contexts. But I find that there’s a opportunity here to provide an explainer without specialist ML/AI/Statistics background knowledge and jargon. The aim of this article is to provide a background on Large Language Model (LLM) progression, and a more informed perspective on how LLMs work and their limitations.
Disclaimer: this article consists of ~95% organic, free-range, fair trade, human-written words. It is not original research but rather secondary research with the aid of LLMs and search engines." />
<meta property="og:url" content="http://localhost:1313/posts/llm-explainer/">
  <meta property="og:site_name" content="RJChow&#39;s Notes">
  <meta property="og:title" content="LLM Explainer">
  <meta property="og:description" content="There’s been quite a few articles that’s been written about AI all over the internet, with various technical depths and contexts. But I find that there’s a opportunity here to provide an explainer without specialist ML/AI/Statistics background knowledge and jargon. The aim of this article is to provide a background on Large Language Model (LLM) progression, and a more informed perspective on how LLMs work and their limitations.
Disclaimer: this article consists of ~95% organic, free-range, fair trade, human-written words. It is not original research but rather secondary research with the aid of LLMs and search engines.">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2025-04-24T00:00:00+00:00">
    <meta property="article:modified_time" content="2025-04-24T00:00:00+00:00">
    <meta property="article:tag" content="Post">
    <meta property="article:tag" content="AI">
    <meta property="article:tag" content="Large Language Models">
    <meta property="article:tag" content="ChatGPT">
    <meta property="article:tag" content="Machine Learning">
    <meta property="article:tag" content="OpenAI">


  <meta itemprop="name" content="LLM Explainer">
  <meta itemprop="description" content="There’s been quite a few articles that’s been written about AI all over the internet, with various technical depths and contexts. But I find that there’s a opportunity here to provide an explainer without specialist ML/AI/Statistics background knowledge and jargon. The aim of this article is to provide a background on Large Language Model (LLM) progression, and a more informed perspective on how LLMs work and their limitations.
Disclaimer: this article consists of ~95% organic, free-range, fair trade, human-written words. It is not original research but rather secondary research with the aid of LLMs and search engines.">
  <meta itemprop="datePublished" content="2025-04-24T00:00:00+00:00">
  <meta itemprop="dateModified" content="2025-04-24T00:00:00+00:00">
  <meta itemprop="wordCount" content="3150">
  <meta itemprop="keywords" content="Post,AI,Large Language Models,ChatGPT,Machine Learning,OpenAI">

  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="LLM Explainer">
  <meta name="twitter:description" content="There’s been quite a few articles that’s been written about AI all over the internet, with various technical depths and contexts. But I find that there’s a opportunity here to provide an explainer without specialist ML/AI/Statistics background knowledge and jargon. The aim of this article is to provide a background on Large Language Model (LLM) progression, and a more informed perspective on how LLMs work and their limitations.
Disclaimer: this article consists of ~95% organic, free-range, fair trade, human-written words. It is not original research but rather secondary research with the aid of LLMs and search engines.">

<link rel="canonical" href="http://localhost:1313/posts/llm-explainer/" />

    <link rel="stylesheet" href="/css/index.css" />


      <script src="/js/main.js" defer></script>
  

<script type="application/ld+json">
{
  "@context": "https://schema.org/",
  "@id": "http://localhost:1313/posts/llm-explainer/",
  "@type": "BlogPosting",
  "copyrightNotice": "RJChow",
  "datePublished": "2025-04-24",
  "description": "There’s been quite a few articles that’s been written about AI all over the internet, with various technical depths and contexts. But I find that there’s a opportunity here to provide an explainer without specialist ML/AI/Statistics background knowledge and jargon. The aim of this article is to provide a background on Large Language Model (LLM) progression, and a more informed perspective on how LLMs work and their limitations.\nDisclaimer: this article consists of ~95% organic, free-range, fair trade, human-written words. It is not original research but rather secondary research with the aid of LLMs and search engines.",
  "headline": "LLM Explainer",
  "isPartOf": {
    "@id": "http://localhost:1313/posts/",
    "@type": "Blog",
    "name": "Posts"
  },
  "keywords": [
    "AI",
    "ChatGPT",
    "Large Language Models",
    "Machine Learning",
    "OpenAI",
    "Post"
  ],
  "mainEntityOfPage": "http://localhost:1313/posts/llm-explainer/",
  "name": "LLM Explainer",
  "timeRequired": "PT15M",
  "url": "http://localhost:1313/posts/llm-explainer/",
  "wordCount": 3150
}
</script>


  </head>
  <body>
    <div class="container mx-auto flex max-w-prose flex-col space-y-10 p-4 md:p-6">
      <header class="flex flex-row items-center justify-between">
        <div>
  <a id="skip-nav" class="sr-only" href="#maincontent">Skip to main content</a>
  <a class="font-semibold" href="/">RJChow&#39;s Notes</a>
</div>

  <nav>
    <ul class="flex flex-row items-center justify-end space-x-4">
    <li>
      <a aria-current="true" class="ancestor" href="/posts/">Posts</a
      >
    </li>
    </ul>
  </nav>


      </header>
      <main class="prose prose-slate relative md:prose-lg prose-h1:text-[2em]" id="maincontent">
        <article class="main">
    <header>
      <h1 class="!mb-1">LLM Explainer</h1><div class="flex flex-row items-center space-x-4">
          <time class="text-sm italic opacity-80" datetime="2025-04-24T00:00:00&#43;00:00"
            >April 24, 2025</time
          >
        </div>
    </header>

    <p>There&rsquo;s been quite a few articles that&rsquo;s been written about AI all over the internet, with various technical depths and contexts. But I find that there&rsquo;s a opportunity here to provide an explainer without specialist ML/AI/Statistics background knowledge and jargon. The aim of this article is to provide a background on Large Language Model (LLM) progression, and a more informed perspective on how LLMs work and their limitations.</p>
<p>Disclaimer: this article consists of ~95% organic, free-range, fair trade, human-written words. It is not original research but rather secondary research with the aid of LLMs and search engines.</p>
<h3 id="large-language-models-llm-are-they-just-word-guessing-programs" class="scroll-mt-8 group">
  Large Language Models (LLM), are they just word guessing programs?
  
    <a href="#large-language-models-llm-are-they-just-word-guessing-programs"
        class="no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block"
        aria-hidden="true" title="Link to this heading" tabindex="-1">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  width="16"
  height="16"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-link w-4 h-4 block"
  viewBox="0 0 24 24"
>
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" />
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" />
</svg>

    </a>
  
</h3>
<p>I&rsquo;ve seen some sentiment (often perceived to be Anti-AI) that LLMs are not to be relied on because they just generate sequences of words. This is somewhat true to an extent, but to completely dismiss them on that basis would be to disregard a large amount of progress on top of them being word sequence generators. To understand why, I will first introduce some working knowledge of LLMs, and then lay out some of the most recent advancements in LLM that resulted in each generational increment.</p>
<h3 id="basics-about-how-llms-work" class="scroll-mt-8 group">
  Basics about how LLMs work
  
    <a href="#basics-about-how-llms-work"
        class="no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block"
        aria-hidden="true" title="Link to this heading" tabindex="-1">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  width="16"
  height="16"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-link w-4 h-4 block"
  viewBox="0 0 24 24"
>
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" />
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" />
</svg>

    </a>
  
</h3>
<h4 id="neural-networks" class="scroll-mt-8 group">
  Neural Networks
  
    <a href="#neural-networks"
        class="no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block"
        aria-hidden="true" title="Link to this heading" tabindex="-1">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  width="16"
  height="16"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-link w-4 h-4 block"
  viewBox="0 0 24 24"
>
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" />
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" />
</svg>

    </a>
  
</h4>
<p>LLMs are an advanced form of deep neural networks (DNN). Neural networks have a training phase first, and then the &lsquo;model&rsquo; which is produced can be used to predict outputs when given inputs (also called inference). They start as a blank (or randomised) slate, and the training process iteratively evolves the software towards the goal of predicting the text sequences present in the training data. The number of iterations is not a fixed number, but rather only terminates when it is determined that the output is sufficiently good enough - keep in mind that it requires a lot of computing power for each training iteration. This is especially so the larger the model and training data set size.</p>
<p>Neural networks are made of numerous small processing units, and the training adjusts how each unit relates to each other. This can give rise to emergent behaviour all on its own. The size of LLMs are actually gigantic (Llama 3.1 405b ~ 1.5TB of RAM, Deepseek R1 ~ <a href="https://snowkylin.github.io/blogs/a-note-on-deepseek-r1.html">720GB of RAM</a>), and since this size is purely how the processing units are connected - you can see just how wildly complex they are. Trying to reverse engineer which units give rise to a given emergent behaviour is similar to neuroscience and thus LLMs are mostly a black box. If that sounds like an exaggeration, there is <a href="https://transformer-circuits.pub/">a series of papers from Anthropic</a> that cover this reverse engineering - and they use techniques like <em><a href="https://transformer-circuits.pub/2022/in-context-learning-and-induction-heads/index.html#argument-ablations">direct ablation</a></em> where specific parts of a miniature model is deleted and its&rsquo; reasoning abilities decline significantly. Wonder if they had to clear it with the ethics board?</p>
<h4 id="tokenisation-language-embedding--attention" class="scroll-mt-8 group">
  Tokenisation, Language Embedding &amp; Attention
  
    <a href="#tokenisation-language-embedding--attention"
        class="no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block"
        aria-hidden="true" title="Link to this heading" tabindex="-1">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  width="16"
  height="16"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-link w-4 h-4 block"
  viewBox="0 0 24 24"
>
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" />
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" />
</svg>

    </a>
  
</h4>
<p>The input to a neural network is a list of numbers. In order for it to be able to process text, the text has to first be transformed into numbers. This process is called tokenisation and language embedding. The classic example of how this works is to represent words in a way such that mathematically, king - man + woman = queen. There&rsquo;s a small detail here where words are not turned into numbers, but first &rsquo;tokenised&rsquo;. This just means that a word like &rsquo;embedding&rsquo; may be split into  &rsquo;embed&rsquo; and &lsquo;##ing&rsquo;, rather than a 1-to-1 representation.</p>
<p>The key insight that let LLMs catch the world&rsquo;s eye is the <a href="https://en.wikipedia.org/wiki/Attention_Is_All_You_Need">&lsquo;attention&rsquo; mechanism</a>. Simply, it gives the neural network the ability to consider not just a word or short word sequences (n-grams, e.g bank loan), but also the context of the entire input, and the position word was in. This means that the word <em>&ldquo;bank&rdquo;</em> in <em>&ldquo;The river near the bank was deep&rdquo;</em> and <em>&ldquo;The bank near the river was crowded&rdquo;</em> will be represented and interpreted differently by the LLM. I had to spend a few moments thinking about that myself.</p>
<p>The representation of each word takes into account all the other words in the prompt, and that means that the number of computations scale as (context length)². Effectively, this means that the computation time required to process the input grows extremely quickly with the length of the context window. (32000 tokens)² = 1 billion, (1 million tokens)² = 1 trillion.</p>
<h4 id="context-window" class="scroll-mt-8 group">
  Context Window
  
    <a href="#context-window"
        class="no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block"
        aria-hidden="true" title="Link to this heading" tabindex="-1">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  width="16"
  height="16"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-link w-4 h-4 block"
  viewBox="0 0 24 24"
>
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" />
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" />
</svg>

    </a>
  
</h4>
<p>This scaling gives rise to a very important but frequently overlooked <a href="https://symbl.ai/developers/blog/guide-to-context-in-llms/">constraint when using LLMs: the context window length</a>. If there&rsquo;s only one thing to take away from this piece of writing, it is to keep in mind this constraint.</p>
<p><strong>The context window length is the maximum amount of input text an LLM can consider at one time when generating a response. If your input exceeds this length, the earliest parts will fall out of the model’s awareness, limiting its ability to fully understand and respond accurately.</strong></p>
<p>I&rsquo;ll come back to the implications of this later, after a chronological order of progression of LLMs. This will help us to understand why LLMs have gained usefulness over the last couple of years.</p>
<h3 id="llm-generations" class="scroll-mt-8 group">
  LLM Generations
  
    <a href="#llm-generations"
        class="no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block"
        aria-hidden="true" title="Link to this heading" tabindex="-1">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  width="16"
  height="16"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-link w-4 h-4 block"
  viewBox="0 0 24 24"
>
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" />
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" />
</svg>

    </a>
  
</h3>
<h4 id="gpt-2-2019-openai" class="scroll-mt-8 group">
  GPT-2 (2019, OpenAI)
  
    <a href="#gpt-2-2019-openai"
        class="no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block"
        aria-hidden="true" title="Link to this heading" tabindex="-1">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  width="16"
  height="16"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-link w-4 h-4 block"
  viewBox="0 0 24 24"
>
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" />
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" />
</svg>

    </a>
  
</h4>
<ul>
<li>First publicly available LLM, actually a next-word predictor that predicts word sequences according to the training data.</li>
<li>Trained on ~40GB of text (~8 million documents, ~10 billion words) from the Internet (WebText).</li>
<li>Included data from news sites, Wikipedia, blogs, books, stories, and discussion forums.</li>
<li>Excluded sources like Wikipedia dumps, social media posts, and codebases.</li>
<li>Context window length: 1024 tokens ~= 750 words. (Amount of prompt + input + chat history that the model can process in one interaction)</li>
</ul>
<h4 id="gpt-3-2020-openai" class="scroll-mt-8 group">
  GPT-3 (2020, OpenAI)
  
    <a href="#gpt-3-2020-openai"
        class="no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block"
        aria-hidden="true" title="Link to this heading" tabindex="-1">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  width="16"
  height="16"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-link w-4 h-4 block"
  viewBox="0 0 24 24"
>
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" />
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" />
</svg>

    </a>
  
</h4>
<ul>
<li>Generational improvement over GPT-2 was the scaling in training efficiency, laid the groundwork for being able to train on much larger training data set and represent more training data.</li>
<li>~570GB of text (~500 billion tokens), more than 10x larger than GPT-2. Training data was carefully curated to be of a high quality.</li>
<li>Sources: A mix of web crawl data, books, and structured knowledge sources. The larger training set and model size likely resulted in higher level conceptual generalisations (such as various task behaviour) being represented in the model.</li>
<li>Context window length: 4096 tokens ~= 3000 words.</li>
<li>Due to that, it displayed an emergent (i.e, not something designed into the model) ability to recognise concepts and infer the requested task in the prompt and adjust its output correspondingly without requiring changes to the model.</li>
<li>This is different to earlier neural networks trained specifically to produce good results for certain tasks, and changing the prompt did not result in a significant difference in behaviour.</li>
<li>Prompt engineering became a thing at this time, as tweaking the prompt could improve performance.</li>
</ul>
<h4 id="gpt-35-2022-openai---first-version-of-chatgpt" class="scroll-mt-8 group">
  GPT-3.5 (2022, OpenAI - first version of ChatGPT)
  
    <a href="#gpt-35-2022-openai---first-version-of-chatgpt"
        class="no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block"
        aria-hidden="true" title="Link to this heading" tabindex="-1">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  width="16"
  height="16"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-link w-4 h-4 block"
  viewBox="0 0 24 24"
>
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" />
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" />
</svg>

    </a>
  
</h4>
<ul>
<li>First model that incorporates human feedback on its responses back into the model. (<a href="https://www.ibm.com/think/topics/rlhf">RLHF</a> = reinforcement learning with human feedback)</li>
<li>Pre-training data likely same as GPT-3, but additional fine tuning using human-labelled instruction-response pairs from various specialised fields (e.g., translation, legal, medical data) and simulated dialogue between GPT and users.</li>
<li>Context window length: 8192 tokens ~= 6000 words.</li>
<li>Humans scored (labelled) the responses according to whatever goals specified, and this feedback was collated and used to adjust the model in order to produce a version that fulfilled the goals well.</li>
<li>It&rsquo;s speculated that expert consultants were hired to provide some or a large amount of content as well as scoring the responses.</li>
<li>This is when GPT caught the attention of the non-ML world as ChatGPT was opened to the public, and impressed them.</li>
<li>Learning to adjust its output using human feedback means that it is not simply predicting word sequences according to the training data, but is actually biasing its output according to its human trainers&rsquo; preferences - improving instruction following and reducing hallucinations.</li>
</ul>
<h4 id="gpt-4-2023-openai--gpt-4o-2024-openai" class="scroll-mt-8 group">
  GPT-4 (2023, OpenAI) / GPT-4o (2024, OpenAI)
  
    <a href="#gpt-4-2023-openai--gpt-4o-2024-openai"
        class="no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block"
        aria-hidden="true" title="Link to this heading" tabindex="-1">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  width="16"
  height="16"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-link w-4 h-4 block"
  viewBox="0 0 24 24"
>
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" />
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" />
</svg>

    </a>
  
</h4>
<ul>
<li>Not much published about the model architecture, size, or its training data.</li>
<li>Speculated that the training data is 13 trillion tokens (~26x larger than GPT-3).</li>
<li>GPT-4o was also trained on non-text content, including images, videos, and audio. It can also directly understand and respond in text, images, videos, and audio without going through an intermediate text representation.</li>
<li>Context window lengths: GPT-4 - 32768 tokens (24000 words), GPT-4o - 128000 tokens (~100000 words).</li>
<li>It is deduced that OpenAI developed optimisations to scale the context window lengths, as the ordinary implementation results in a quadratic scaling (4x window increase = 16x memory required).</li>
<li>Speculation that it doesn&rsquo;t use one big model, but rather multiple smaller models that have different fields of expertise resulting from specialised training data. (Mixture of experts architecture)</li>
<li>Fine-tuned using human feedback for various goals, such as not producing harmful responses as well as appropriately generating responses that delegate tasks to external tools (function / tool calling). Also fine-tuned with syntactically correct JSON so that it reliably produces JSON output, used for function calling.</li>
</ul>
<h4 id="gemini-10-15-dec2023-google-deepmind" class="scroll-mt-8 group">
  Gemini 1.0, 1.5 (Dec 2023, Google DeepMind):
  
    <a href="#gemini-10-15-dec2023-google-deepmind"
        class="no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block"
        aria-hidden="true" title="Link to this heading" tabindex="-1">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  width="16"
  height="16"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-link w-4 h-4 block"
  viewBox="0 0 24 24"
>
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" />
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" />
</svg>

    </a>
  
</h4>
<ul>
<li>Inherently multimodal, able to accept mixed input types (text, images, audio, video) within the same context as it was trained on a massive corpus of web documents, books, and code, including image, audio, and video data</li>
<li>Family of 3 models (Ultra, Pro, Nano) with different model sizes and computational requirements</li>
<li>At launch, Gemini 1.0 had a context window length of 32768 tokens</li>
<li>Shortly after in Feb 2024, Gemini 1.5 Pro was released with a context window length of 1.5 million tokens</li>
<li>Massive context length was praised for allowing developers to dump entire code repositories into the context, allowing the LLM to have the context to work on existing projects</li>
</ul>
<h4 id="llama-31-2024-meta" class="scroll-mt-8 group">
  Llama 3.1 (2024, Meta)
  
    <a href="#llama-31-2024-meta"
        class="no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block"
        aria-hidden="true" title="Link to this heading" tabindex="-1">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  width="16"
  height="16"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-link w-4 h-4 block"
  viewBox="0 0 24 24"
>
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" />
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" />
</svg>

    </a>
  
</h4>
<ul>
<li>Variants of 8 billion, 70 billion, 405 billion parameters</li>
<li>8 Billion runs on ~16GB of RAM, so it&rsquo;s quite accessible</li>
<li>Has a context window length of 128000 tokens (~100000 words)</li>
<li>Speculated that the training data is trillions of tokens, seems like they used some <a href="https://www.tomshardware.com/tech-industry/artificial-intelligence/meta-defends-using-pirated-material-claims-its-legal-if-you-dont-seed-content">illegally obtained pirated material</a> too!</li>
<li>Model weights were released publicly so you could run it on your own hardware (if you had big enough hardware)</li>
<li>Narrowed the gap between open sourced models and closed (i.e OpenAI) models, it performed well enough to be compared to GPT-4</li>
</ul>
<h4 id="o1-o3-sept2024-openai" class="scroll-mt-8 group">
  O1, O3 (Sept2024, OpenAI)
  
    <a href="#o1-o3-sept2024-openai"
        class="no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block"
        aria-hidden="true" title="Link to this heading" tabindex="-1">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  width="16"
  height="16"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-link w-4 h-4 block"
  viewBox="0 0 24 24"
>
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" />
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" />
</svg>

    </a>
  
</h4>
<ul>
<li>Context window lengths: O1-mini: 128000 tokens, O1: 32000 tokens for ChatGPT plus ($15/month), 128000 tokens for ChatGPT pro ($200/month), O3-mini: 200000 tokens.</li>
<li>Training data included synthetic reasoning chains produced by GPT-4o, and annotated by another model CriticGPT.</li>
<li>Apparent reasoning ability by being tuned to produce an internal monologue response that decomposes problems into smaller sub-problems, and attempting to find solutions. (Chain of thought)</li>
<li>Tuning rewarded the production of coherent internal monologues, and the internal monologue also takes up the output limit.</li>
<li>OpenAI found that there was a corresponding improvement in performance on reasoning ability tests when the model was incentivised to produce longer monologues. (Inference time scaling)</li>
<li>O3 was further tuned to spend more time reflecting, and had a &rsquo;thinking effort&rsquo; knob from low to high which gave better results as more effort was spent &rsquo;thinking&rsquo;</li>
<li>O3 supports web browsing tool usage unlike O1, and uses this for the &lsquo;Deep Research&rsquo; mode</li>
<li>From the restrictions on usage, it is evident that these models are very expensive to run</li>
</ul>
<p>(GPT 4.5 was released after I started writing this so I&rsquo;m not including it. Also apologies to all the other LLM lineages that I did not include, please don&rsquo;t take it personally in the future if/when you become SkyNet or HAL 9000.)</p>
<h3 id="hallucinations-why-do-they-happen" class="scroll-mt-8 group">
  Hallucinations, why do they happen?
  
    <a href="#hallucinations-why-do-they-happen"
        class="no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block"
        aria-hidden="true" title="Link to this heading" tabindex="-1">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  width="16"
  height="16"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-link w-4 h-4 block"
  viewBox="0 0 24 24"
>
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" />
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" />
</svg>

    </a>
  
</h3>
<p>As explained earlier, LLM model weights consist of relationships between processing units, trained by repetition on a large corpus of data.  One thing that is high quality and extremely consistent within this corpus is grammar (specifically English grammar) and spelling. This is noticeably reflected in the LLMs output, they rarely ever make grammatical or spelling errors. TODO: deep research link</p>
<p>However, compare that to facts. Imagine that every line of text used for training has perfect grammar and spelling (this is very likely to be the case since training data is well curated). Whereas for facts, the distribution is much more varied. Even when only true facts are included, including Fact #1 may necessarily exclude Fact #2 &hellip; #n from that line of training data. This is taken to an even farther extreme for niche information, which may not be repeated much at all in the training corpus.</p>
<p>Therefore, this gives rise to what we have termed &lsquo;hallucinations&rsquo;. The LLM needs to generate an output, and what it is very strong at is a grammatically coherent, and probably a quite-convincing writing style. It does not have a concept of &rsquo;looking up my training data&rsquo;, since that data has long since been transformed into model weights. It does not even have the capability to introspect on its model weights!</p>
<h3 id="why-does-a-larger-llm-context-window-make-them-more-capable" class="scroll-mt-8 group">
  Why does a larger LLM Context Window make them more capable?
  
    <a href="#why-does-a-larger-llm-context-window-make-them-more-capable"
        class="no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block"
        aria-hidden="true" title="Link to this heading" tabindex="-1">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  width="16"
  height="16"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-link w-4 h-4 block"
  viewBox="0 0 24 24"
>
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" />
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" />
</svg>

    </a>
  
</h3>
<p>From the timeline above, we can see that despite the scaling challenges, context window lengths have increased tremendously. Prior to GPT-4, context lengths were quite limited (~6000 words) and some part of this would have been taken up by the system prompt. With this limitation, users often noticed that performance dropped off after the chat session got to a certain length, and determined that ChatGPT was generating a summary of earlier messages whenever it got too long. These days the context lengths are much longer, and it&rsquo;s <a href="https://openai.com/index/finding-gpt4s-mistakes-with-gpt-4/">hypothesised</a> that LLMs are also trained to ignore irrelevant information to reduce the chances of being side tracked.</p>
<p>From my own experience and anecdotal accounts, it would seem that the fact-regurgitation abilities of GPT-4 to GPT-4o to GPT-4.5 hasn&rsquo;t really improved all that much, and OpenAI seems to have focused its resources on improving the reasoning abilities of the O* series.</p>
<br />
<h6 id="aside" class="scroll-mt-8 group">
  &lt;aside&gt;
  
    <a href="#aside"
        class="no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block"
        aria-hidden="true" title="Link to this heading" tabindex="-1">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  width="16"
  height="16"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-link w-4 h-4 block"
  viewBox="0 0 24 24"
>
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" />
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" />
</svg>

    </a>
  
</h6>
<h7 id="why-dont-we-just-ingest-all-of-our-proprietary-knowledgebase-into-an-llm" class="scroll-mt-8 group">
  Why don&rsquo;t we just ingest all of our proprietary knowledgebase into an LLM??
  
    <a href="#why-dont-we-just-ingest-all-of-our-proprietary-knowledgebase-into-an-llm"
        class="no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block"
        aria-hidden="true" title="Link to this heading" tabindex="-1">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  width="16"
  height="16"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-link w-4 h-4 block"
  viewBox="0 0 24 24"
>
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" />
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" />
</svg>

    </a>
  
</h7>
<p>This context window length limitation is why we haven&rsquo;t just gone and &lsquo;<em>ingested all of the knowledgebase into an LLM</em>&rsquo;, as often wished for in the LLM wishlist.</p>
<p>Okay, so why don&rsquo;t we use the knowedgebase to train or fine tune an LLM?</p>
<p>It can be thought of this way: the model weights is a soup of grammar, and abstract concepts.</p>
<p>The larger the model, the more abstract concepts it is capable of recognising. We do not have a high quality, curated data set in our proprietary knowledgebase (unfortunately).</p>
<p>There is just way too much noise, and very disparate topics with inconsistent terminology.</p>
<p>&lt;/aside&gt;</p>
<br />
<p>With the much larger context windows recently, it has become possible to insert additional relevant information (Retrieval Augmented Generation, RAG) that might be useful in generating the answer. The more relevant information the LLM has in its working memory, the more likely it is to produce a useful response.</p>
<p><em><strong>The most useful AI tools these days are industry-leading because they have wrapped the LLMs with very capable context retrieval systems.</strong></em></p>
<p>I did up a small report previously, comparing the Deep Research reports of OpenAI, Perplexity, and Gemini. It can be inferred from the results that OpenAI&rsquo;s search returns better results than even Google (What&rsquo;s going on there??), and combined with the better reasoning abilities of O1/O3, the report is actually coherent.</p>
<p>In that report I wrote that both Gemini and Perplexity retrieves facts that are not actually applicable to the specific nuance at hand, and conflates that in the results. This also gave rise to &ldquo;hallucinations&rdquo;. I&rsquo;m not really sure I would call them hallucinations, just bad research and poor reasoning. An unconscientious human without prior knowledge in this area, would probably have made the same mistakes.</p>
<p>For now, most systems in production (AFAIK) don&rsquo;t actually use LLMs&rsquo; novel technological improvements in their search engines. Using LLM technologies in search engines is an <a href="https://eugeneyan.com/writing/recsys-llm/">area of active research</a>, so perhaps we&rsquo;ll see more interesting results there soon.</p>
<h4 id="fine-tuning--reinforcement-learning-with-human-feedback-rlhf" class="scroll-mt-8 group">
  Fine tuning &amp; Reinforcement Learning with Human Feedback (RLHF)
  
    <a href="#fine-tuning--reinforcement-learning-with-human-feedback-rlhf"
        class="no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block"
        aria-hidden="true" title="Link to this heading" tabindex="-1">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  width="16"
  height="16"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-link w-4 h-4 block"
  viewBox="0 0 24 24"
>
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" />
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" />
</svg>

    </a>
  
</h4>
<p>I haven&rsquo;t really touched on this topic, and it could probably fill a tome(s) on its own if we went deep into it.  Earlier I mentioned that LLMs are trained on a large training corpus, and at some point in the timeline &ldquo;Reinforcement Learning with Human Feedback&rdquo; (RLHF) started being used to improve the LLMs. This process means that the LLMs output are no longer just a statistical reflection of the training data. It&rsquo;s another step in the process, and it adjusts the weight by rewarding the training process for producing outputs that humans find ideal.</p>
<p>The iterative process of RLHF and fine tuning selects for LLMs that produce logical output, and is good at following instructions (given in the prompt). It then becomes inaccurate to say that LLMs merely produce word sequences randomly, but more accurate to say that they have been trained to mimic human reasoning patterns.</p>
<p>Does the ability to mimic human reasoning patterns mean that they are capable of reasoning and critical thinking? That&rsquo;s a difficult to quantify criteria, and it becomes more of a philosophical question. What is intelligence?</p>
<p>The benchmarks do certainly show that the latest frontier models are better at solving math problems than a significant proportion of the human population.</p>
<p>Think about it - would a random word generator be able to break down this task and perform it:</p>
<p><em>&ldquo;Reduce all the title headings in this article by one level, and capitalise them to title case&rdquo;</em></p>
<p>Performing this task would require knowledge of these abstract concepts and reasoning about the input article:</p>
<ul>
<li>being able to identify title headings</li>
<li>the concept of capital-letters and small-letters</li>
<li>what title case is</li>
<li>reproducing the original text without modifying it against the instructions</li>
</ul>
<p>This is actually a task that even a few generations old LLMs are capable of, and by now I think that most people would not think that it is novel or controversial to use LLMs for such a use case.</p>
<h4 id="conclusion" class="scroll-mt-8 group">
  Conclusion
  
    <a href="#conclusion"
        class="no-underline hidden opacity-50 hover:opacity-100 !text-inherit group-hover:inline-block"
        aria-hidden="true" title="Link to this heading" tabindex="-1">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  width="16"
  height="16"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-link w-4 h-4 block"
  viewBox="0 0 24 24"
>
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71" />
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71" />
</svg>

    </a>
  
</h4>
<p>I&rsquo;ve personally maintained the stance that LLMs enable a new mode of Human-Computer Interaction, just like a mouse-driven Graphical User Interface did. This lengthy writeup does support my opinion, and that LLMs are a front-end to other knowledge retrieval systems, operated by natural language. It can also interface with tools, and it is capable of inferring that you require certain tool usage while trying to complete the task it has been given.</p>
<p>The large increase in context window length has enabled the architectures of &ldquo;retrieval augmented generation&rdquo;, and &ldquo;agentic AI&rdquo;. Agentic AI simply means allowing the LLM to expand the task instructions and breaking it down into sub-problems that can either be reasoned through or require the usage of tools to resolve.</p>
<p>When we use LLMs in our daily work, it is important to remember that they cannot read your mind, and they generally do not have specialist, niche knowledge. What they are is a good representation of the abstract concepts that humans take for granted. When provided with relevant information, they can make use of this understanding of abstract concepts, and synthesise the information into a workable and coherent output.</p>

  </article>
    <aside class="not-prose flex flex-col space-y-8 border-t pt-6">
    <section class="flex flex-col space-y-4">
      <h2 class="flex flex-row items-center space-x-2 text-lg font-semibold">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-tags h-4 w-4"
  viewBox="0 0 24 24"
  aria-hidden="true"
>
  <path d="m15 5 6.3 6.3a2.4 2.4 0 0 1 0 3.4L17 19" />
  <path
    d="M9.586 5.586A2 2 0 0 0 8.172 5H3a1 1 0 0 0-1 1v5.172a2 2 0 0 0 .586 1.414L8.29 18.29a2.426 2.426 0 0 0 3.42 0l3.58-3.58a2.426 2.426 0 0 0 0-3.42z"
  />
  <circle cx="6.5" cy="9.5" r=".5" fill="currentColor" />
</svg>

        <span>Tags</span>
      </h2>

      <ul class="not-prose ml-6 flex flex-row flex-wrap items-center space-x-2">
          <li>
            <a href="/tags/post/" class="taxonomy tag">post</a>
          </li>
          <li>
            <a href="/tags/ai/" class="taxonomy tag">AI</a>
          </li>
          <li>
            <a href="/tags/large-language-models/" class="taxonomy tag">Large Language Models</a>
          </li>
          <li>
            <a href="/tags/chatgpt/" class="taxonomy tag">ChatGPT</a>
          </li>
          <li>
            <a href="/tags/machine-learning/" class="taxonomy tag">Machine Learning</a>
          </li>
          <li>
            <a href="/tags/openai/" class="taxonomy tag">OpenAI</a>
          </li>
      </ul>
    </section>
    <section class="flex flex-col space-y-4" aria-hidden="true">
      <h2 class="flex flex-row items-center space-x-2 text-lg font-semibold">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-chart-network h-4 w-4"
  viewBox="0 0 24 24"
  aria-hidden="true"
>
  <path
    d="m13.11 7.664 1.78 2.672M14.162 12.788l-3.324 1.424M20 4l-6.06 1.515M3 3v16a2 2 0 0 0 2 2h16"
  />
  <circle cx="12" cy="6" r="2" />
  <circle cx="16" cy="12" r="2" />
  <circle cx="9" cy="15" r="2" />
</svg>

        <span>Graph</span>
      </h2>

      <content-network-graph
  class="h-64 ml-6"
  data-endpoint="/graph/index.json"
  page="/posts/llm-explainer/"
></content-network-graph>

    </section>
    <section class="flex flex-col space-y-4">
      <h2 class="flex flex-row items-center space-x-2 text-lg font-semibold">
        <svg
  xmlns="http://www.w3.org/2000/svg"
  fill="none"
  stroke="currentColor"
  stroke-linecap="round"
  stroke-linejoin="round"
  stroke-width="2"
  class="lucide lucide-newspaper h-4 w-4"
  viewBox="0 0 24 24"
  aria-hidden="true"
>
  <path
    d="M4 22h16a2 2 0 0 0 2-2V4a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v16a2 2 0 0 1-2 2Zm0 0a2 2 0 0 1-2-2v-9c0-1.1.9-2 2-2h2M18 14h-8M15 18h-5"
  />
  <path d="M10 6h8v4h-8V6Z" />
</svg>

        <span>Posts</span>
      </h2>
        <section class="flex flex-col space-y-1">
          <h3 class="flex flex-row items-center space-x-2 text-sm font-semibold">
            <svg
  xmlns="http://www.w3.org/2000/svg"
  viewBox="0 0 256 256"
  class="h-4 w-4"
  aria-hidden="true"
>
  <path
    fill="currentColor"
    d="M222.16 153.26a8 8 0 0 1-1 11.25c-17.36 14.38-32.86 19.49-47 19.49-18.58 0-34.82-8.81-49.93-17-25.35-13.75-47.24-25.63-79.07.74a8 8 0 1 1-10.22-12.3c40.17-33.27 70.32-16.92 96.93-2.48 25.35 13.75 47.24 25.62 79.07-.75a8 8 0 0 1 11.22 1.05m-177-49.46c31.83-26.37 53.72-14.5 79.07-.75 15.11 8.2 31.35 17 49.93 17 14.14 0 29.64-5.11 47-19.49a8 8 0 1 0-10.22-12.3c-31.83 26.37-53.72 14.49-79.07.74-26.61-14.43-56.76-30.79-96.93 2.48a8 8 0 0 0 10.17 12.32Z"
  />
</svg>

            <span>Related</span>
          </h3>

          <ol class="not-prose ml-6">
    <li>
      <article class="flex flex-row items-center">
        <header class="grow">
          <h3>
            <a
              href="/posts/hello-world/"
              class="truncate text-sm underline decoration-slate-300 decoration-2 underline-offset-4 hover:decoration-inherit"
              title="Hello World"
              >Hello World</a
            >
          </h3>
        </header>
      </article>
    </li>
</ol>

        </section>
    </section>
</aside>


      </main>
      <footer class="mt-20 border-t border-neutral-100 pt-2 text-xs">
        <section class="items-top flex flex-row justify-between opacity-70">
  <div class="flex flex-col space-y-2">
      <p>Copyright &copy; 2025, RJChow.</p>

  </div>
    <div>
      <a
        href="https://github.com/michenriksen/hugo-theme-til"
        title="Today I Learned &#8212; A Hugo theme by Michael Henriksen"
        data-theme-version="0.6.0"
        >theme: til</a
      >
    </div>
</section>

      </footer>
    </div>
    
  </body>
</html>
